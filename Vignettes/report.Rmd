---
title: "Data_processing"
author: "Chiara Huwiler"
date: "2023-11-30"
output: 
  html_document:
    toc: yes
    toc_float:
      collapsed: true
bibliography: references.bib
---

```{r load_packages, echo=FALSE}
# Loading packages
library(rgbif)
library(dplyr)
library(ggplot2)
library(tidyr)
library(stringr)
library(lubridate)
library(countrycode)
library(rnaturalearth)
library(rnaturalearthdata)
library(RColorBrewer)
library(magick)
library(gganimate) # Version 1.0.7
library(transformr) # Version 0.1.3
library(sf)
library(here)
```

This is the report for the semester project of the course ´Proseminar in Geocomputation and Earth Observation´ HS23 and shows an Applied Geo-Data Science project.

# Introduction

Pizza is probably one of the most famous dishes in Europe and probably in most parts of the world. As popular as pizza is, there are numerous ways to prepare it and what toppings are used. But nevertheless, ingredients are coming from all over the world, and those have not always been local to Europe or other parts of the world.

So this project aims to answer the following research question: "How is the historical journey of some selected pizza ingredients over continents and time, and how can the results be presented in an appealing animation?"

Exploring the global history of the ingredients of a pizza helps us not only to enrich our understanding of the past but also to appreciate more the cultural diversity that has shaped our culinary experiences. The journey of food around the world isn't a new topic, as shown by the study Origins of Food Crops [@khoury2016], which connects countries worldwide. In association with this study, a [website](https://blog.ciat.cgiar.org/origin-of-crops/) has been created to show plotted data, for example, where food crops come from and where they are eaten now.

(Background, Relevance, Motivation)

# Methods and Data

As I said in the introduction, there are a lot of different ways to prepare a pizza. For this project, an easy-to-prepare dough is used from [Betty Bossi](https://www.bettybossi.ch/de/Home/Index), which is a cooking recipe provider. This [recipe](https://www.bettybossi.ch/de/Rezept/ShowRezept/BB_ITKU120801_0243A-40-de) contains water, salt, flour (mostly wheat), yeast, and olive oil. Possible vegetarian topics include corn, tomatoes, onions, paprika, cheese, and basil. For this project, only species (or scientific genera) are considered and no processed food. So the ingredients considered are: wheat (Triticum), olive (Olea europaea), corn (Zea mays), tomatoes (Solanum lycopersicum), onions (Allium cepa), paprika (Capsicum), and basil (Ocimum basilicum).

To get the needed data about the ingredients, the database "Global Biodiversity Information Facility" [(GBIF)](https://www.gbif.org/) is used as the basis for this project. GBIF was originally planned to be an international mechanism to make biodiversity data and information accessible worldwide. And then it was established in 2001 with the approval of the Organization for Economic Cooperation and Development (OECD). GBIF provides data on all types of life on earth and, for this project, especially important records on occurrences. These occurrence records are here used to identify the earliest appearance of a species on a continent. Each occurrence is provided with the scientific name, country or area, coordinates, year, basis of record, data set, and more. For downloading the data, the package @rGBIF can be used, but only with a free GBIF account. To avoid this, the data downloading is done and described in more detail in the other markdown [Downloading_data](Downloading_data.RMD). The data used in this markdown is therefore saved in the folder Data_ingredients [(combined_data)](../Data_ingredients/cleaned/combined_data.csv). First, the data for the seven selected genera (also saved in the mentioned folder) were downloaded individually and filtered by some quality markers (like removing absent records and removing data with high coordinate uncertainty). After this, the data got shortened to the only needed columns (scientific name, year, and country code). The rows with missing values in these columns were excluded. At the end, the seven data files got merged into one (combined_data) for easier handling in the follow-up.

### Merging UNSD_M49.csv with combined_data.csv

To find out when a species appeared on a continent, the occurrence data needs to be extended with information about continents. This is done with the data set UNSD_M49 from the [United Nations (UN)](https://unstats.un.org/unsd/methodology/m49/overview/), where geographic regions are defined. According to the UN, each country has a defined region and subregion. As regions, Africa, Antarctica, the Americas, Asia, Europe, and Oceania are defined. There is no data provided in GBIF for Antarctica, so this is ignored, whereas the subregion is used for the Americas, so Latin America and the Caribbean (renamed South America) and Northern America (renamed North America).

In the combined_data set, there are not only the genus but also the species and subspecies mentioned, e. g., for Triticum L. there are around 134 different ones. For that reason, the scientificName column gets filtered for the words Triticum, Olea, Zea, Solanum, Allium, Capsicum and Ocimum. Those define them and are then altered to the scientific name, respectively, of their genus.

```{r}
combined_data <- read.csv(here("Data_ingredients", "cleaned", "combined_data.csv"))
UNSD_M49 <- read.csv(here("Data", "UNSD_M49.csv"))

# Remove rows with NA in countryCode
combined_data_e <- combined_data[complete.cases(combined_data$countryCode), ]

# Separate the UNSD_M49 data frame by semicolon
UNSD_M49_split <- separate(data = UNSD_M49,
                            col = "Region_Code.Region.Name.Sub.region.Code.Sub.region.Name.ISO_alpha2_Code",
                            into = c("Region_Code", "Region_Name", "Subregion_Code", "Subregion_Name", "ISO_alpha2_Code"),
                            sep = ";", fill = "right", convert = TRUE)


# Find rows with missing values after separation
problematic_rows <- apply(UNSD_M49_split, 1, function(row) any(is.na(row)))

# Remove problematic rows from UNSD_M49_split
UNSD_M49_c <- UNSD_M49[complete.cases(UNSD_M49), ]

# Merging data frames
merged_data <- merge(combined_data_e, UNSD_M49_split, by.x = "countryCode", by.y = "ISO_alpha2_Code", all.x = TRUE)

# Check if "americas" is present in Region_Name, if true, use Subregion_Name
merged_data$Region_Name <- ifelse(merged_data$Region_Name == "Americas", merged_data$Subregion_Name, merged_data$Region_Name)

# Remove Subregion_Name column if it's no longer needed
merged_data <- merged_data[, !(names(merged_data) %in% c("Subregion_Name"))]

# Changing the UN Definition Names
merged_data$Region_Name <- ifelse(merged_data$Region_Name == "Latin America and the Caribbean", "South America", merged_data$Region_Name)

merged_data$Region_Name <- ifelse(merged_data$Region_Name == "Northern America", "North America", merged_data$Region_Name)

# Keeping only the needed columns
merged_data <- merged_data[, c("countryCode", "X", "scientificName", "year", "Region_Name")]

# Extracting species names (remove anything after the space)
merged_data$speciesName <- gsub(" .*", "", merged_data$scientificName)

# Filtering based on species of interest
species_sup <- c("Triticum", "Olea", "Zea", "Solanum", "Allium", "Capsicum", "Ocimum")


# Remove rows with NA or are blank in Region_Name
filtered_data <- merged_data %>%
  filter(!is.na(Region_Name) & Region_Name != "") %>%
  filter(speciesName %in% species_sup)

# Adding the mapping of species names to scientific names
species_mapping <- c("Triticum" = "Triticum L.",
                      "Olea" = "Olea europaea L.",
                      "Zea" = "Zea mays L.",
                      "Solanum" = "Solanum lycopersicum L.",
                      "Allium" = "Allium cepa L.",
                      "Capsicum" = "Capsicum L.",
                      "Ocimum" = "Ocimum basilicum L.")

# Replacing speciesName with scientific names based on the mapping
filtered_data$speciesName <- species_mapping[filtered_data$speciesName]


# Save merged_data to the "Data" folder
write.csv(merged_data, here("Data", "merged_data.csv"), row.names = FALSE)

# Save filtered_data to the "Data" folder
write.csv(filtered_data, here("Data", "filtered_data.csv"), row.names = FALSE)


```

### Better understanding the data

```{r}
# Scientific Names of the seven ingredients
species_of_interest <- c("Triticum L.", "Olea europaea L.", "Zea mays L.", "Solanum lycopersicum L.", "Allium cepa L.", "Capsicum L.", "Ocimum basilicum L.")

# Filtering the data for species_of_interest and calculate the counts
filtered_data1 <- filtered_data %>%
  filter(speciesName %in% species_of_interest) %>%
  group_by(speciesName) %>%
  summarise(count = n())

# Setting the plot width
options(repr.plot.width = 10) 

# Arranging the data by count in descending order
filtered_data1 <- filtered_data1 %>% 
  arrange(desc(count))

# Creating the plot
sample_number <- ggplot(filtered_data1, aes(x = reorder(speciesName, -count), y = count)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  geom_text(aes(label = count), vjust = -0.5, color = "black") +
  labs(title = "Number of Samples per Genus",
       x = "Species",
       y = "Number of Samples") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.margin = margin(b = 50)) 


# Printing the plot
 print(sample_number)
```

```{r}
# Aggregating information
     count_data <- filtered_data %>%
     group_by(year, speciesName) %>%
     summarise(count = n())
 
# Plotting a dot plot
 dot_plot <- ggplot(count_data, aes(x = year, y = speciesName, size = count)) +
     geom_point(color = "skyblue") +
     labs(title = "Dot Plot: Sample Size by Year and Species",
          x = "Year",
          y = "Species",
          size = "Sample Size") +
     theme_minimal()
 
# Printing the plot
print(dot_plot)
```

### Filtering Data

```{r}
# Filtering merged_data for samples per continent
samples_per_continent <- filtered_data %>%
     group_by(Region_Name) %>%
     summarise(Number_of_Samples = n())
 
 # Print the result
 print(samples_per_continent)
```

#### Earliest appearance per continent (EAC)

Here, the new combined and then filtered data set (filtered_data.csv), is filtered for the earliest appearance of each species per continent.

```{r}
# Loading filtering_EAC function
source(here("R_functions", "filtering_EAC.R"))

```

#### Plotting the EAC

For a more useful presentation of the data, the EAC is plotted. Therefore, the continents are ordered by their earliest appearance year and are then plotted in a timeline.

```{r}
# Loading the function to plot the EAC on a timeline
source(here("R_functions", "plotting_EAC.R"))

```

### Plotting the Data on a Map

As there is now information available about the EAC of each genera, it all gets plotted on a world map. This map shows the earliest appearance of a ingredient from the GBIF Database on an continent.

```{r}
# Loading world data
world <- ne_countries(scale = "medium", returnclass = "sf")

# Standardizing continent names in world data
world <- world %>%
  mutate(region_un = case_when(
    region_un %in% c("Asia", "Oceania", "South America", "North America", "Africa", "Europe") ~ region_un,
    TRUE ~ "Other"
  ))

# Load function to map EAC on a world map
source(here("R_functions", "EAC_world_map.R"))

# Looping over species names and create map plots
for (species_name in species_of_interest) {
  cat("Processing species:", species_name, "\n")

  # Creating the map plot
  create_species_map(species_name)
}
```

### Animating the maps

Here the maps get animated with the package @gganimate.

```{r}
# Loading function to animate the maps
 source(here("R_functions", "EAC_wm_animation.R"))
 
# Looping over species names and create map plots
 for (species_name in species_of_interest) {
  cat("Processing species:", species_name, "\n")
  create_species_map(species_name)
}
```

# Results

The underlying code presents, as a result, the spread of the seven chosen ingredients per continent and time on an animated world map. As the feasibility example has already shown, there is an issue with the data from GBIF. Although GBIF has data from 1000 to 2023, that doesn't mean there is data provided for each species during this time period. Also, the availability of data on GBIF depends a lot on the scientific stand, whether data is provided to GBIF and whether it meets the [standards of GBIF](https://www.gbif.org/what-is-gbif#:~:text=This%20knowledge%20derives%20from%20many,in%20recent%20days%20and%20weeks). So the first appearance date only represents the first appearance that is registered in the GBIF database.

(Reports the results in a logical order that facilitates reading - from the general pattern to the details. Basic and central finding first, then the nuance.)

# Discussion

(Explain what the results mean in relation to the question stated in the Introduction. Discuss caveats, compare to earlier findings, and explain the relevance of your results.)
